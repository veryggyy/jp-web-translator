import streamlit as st
import requests
from bs4 import BeautifulSoup
from deep_translator import GoogleTranslator
import time

# 1. é é¢é…ç½®å„ªåŒ–
st.set_page_config(page_title="JP æ—¥æ–‡åŠ©æ‰‹ PRO", page_icon="ğŸ‡¯ğŸ‡µ", layout="wide")

# åŠ å…¥æ›´å°ˆæ¥­çš„ CSS æ¨£å¼
st.markdown("""
    <style>
    .main { background-color: #0e1117; }
    .stTextInput>div>div>input { background-color: #262730; color: white; }
    .trans-card { 
        background-color: #1e1e1e; 
        padding: 20px; 
        border-radius: 15px; 
        border-left: 6px solid #00d4ff;
        margin-bottom: 15px;
        box-shadow: 0 4px 6px rgba(0,0,0,0.3);
    }
    .orig-text { color: #888; font-size: 0.85rem; margin-top: 8px; font-style: italic; }
    .zh-text { color: #ffffff; font-size: 1.1rem; line-height: 1.6; font-weight: 500; }
    </style>
    """, unsafe_allow_html=True)

st.title("ğŸš€ JP æ—¥æ–‡ç¶²é å°ˆæ¥­ç¿»è­¯ (åŠ é€Ÿç‰ˆ)")
st.caption("æ¡ç”¨æ‰¹æ¬¡ç¿»è­¯æŠ€è¡“ï¼Œå¤§å¹…æå‡è®€å–é€Ÿåº¦èˆ‡ç¹ä¸­ç²¾æº–åº¦")

# 2. æ ¸å¿ƒåŠŸèƒ½ï¼šæ‰¹æ¬¡ç¿»è­¯å¼•æ“
def batch_translate(text_list):
    if not text_list: return []
    # å°‡å¤šå€‹æ®µè½ç”¨ç‰¹æ®Šçš„æ›è¡Œç¬¦è™Ÿé€£æ¥ï¼Œä¸€æ¬¡é€å‡ºï¼ˆæ¸›å°‘ç¶²è·¯è«‹æ±‚æ¬¡æ•¸ï¼‰
    combined_text = "\n\n---NEXT---\n\n".join(text_list)
    try:
        translated = GoogleTranslator(source='ja', target='zh-TW').translate(combined_text)
        return translated.split("\n\n---NEXT---\n\n")
    except:
        return [GoogleTranslator(source='ja', target='zh-TW').translate(t) for t in text_list]

# 3. è¼¸å…¥å€
url = st.text_input("è«‹è²¼ä¸Šæ—¥æ–‡ç¶²å€ï¼š", placeholder="https://ncode.syosetu.com...")

if url:
    try:
        start_time = time.time()
        with st.status("æ­£åœ¨é€²è¡Œæ·±åº¦è§£æèˆ‡æ‰¹æ¬¡ç¿»è­¯...", expanded=True) as status:
            # æŠ“å–ç¶²é  (æ¨¡æ“¬çœŸå¯¦ç€è¦½å™¨é˜²æ­¢è¢«æ“‹)
            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
            res = requests.get(url, headers=headers, timeout=10)
            res.encoding = 'utf-8'
            soup = BeautifulSoup(res.text, 'lxml')
            
            # é‡å°å°èªªç¶²ç«™ï¼ˆå¦‚ syosetuï¼‰çš„ç‰¹æ®Šå„ªåŒ–ï¼šæŠ“å–ä¸»é«”å…§å®¹
            # å¦‚æœæ˜¯å°èªªï¼Œé€šå¸¸åœ¨ .novel_view æˆ– #novel_honbun
            main_content = soup.find_all(['p', 'h1', 'h2'])
            
            raw_paragraphs = []
            for p in main_content:
                text = p.get_text().strip()
                if len(text) > 2: # éæ¿¾æ‰ç©ºç™½è¡Œ
                    raw_paragraphs.append(text)

            # é¡¯ç¤ºæ¨™é¡Œ
            page_title = soup.title.string if soup.title else "æ—¥æ–‡ç¶²é "
            st.header(GoogleTranslator(source='ja', target='zh-TW').translate(page_title))
            st.write(f"â±ï¸ è§£æè€—æ™‚: {round(time.time() - start_time, 2)} ç§’")
            st.divider()

            # åŸ·è¡Œåˆ†æ‰¹ç¿»è­¯ï¼ˆæ¯ 10 æ®µä¸€çµ„ï¼Œå¹³è¡¡é€Ÿåº¦èˆ‡ç©©å®šæ€§ï¼‰
            batch_size = 10
            for i in range(0, len(raw_paragraphs), batch_size):
                batch = raw_paragraphs[i:i + batch_size]
                translated_batch = batch_translate(batch)
                
                for orig, tran in zip(batch, translated_batch):
                    st.markdown(f"""
                        <div class="trans-card">
                            <div class="zh-text">{tran}</div>
                            <div class="orig-text">{orig}</div>
                        </div>
                    """, unsafe_allow_html=True)
            
            status.update(label="âœ… ç¿»è­¯å®Œæˆï¼", state="complete")

    except Exception as e:
        st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}ã€‚é€™å¯èƒ½æ˜¯å› ç‚ºç¶²ç«™è¨­æœ‰é˜²çˆ¬èŸ²æ©Ÿåˆ¶ã€‚")
