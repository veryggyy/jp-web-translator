import streamlit as st
import requests
from bs4 import BeautifulSoup
from deep_translator import GoogleTranslator
import time

# 1. é é¢é…ç½®ï¼šç¶­æŒæ¥µè‡´å¤œé–“æ²ˆæµ¸æ¨¡å¼
st.set_page_config(page_title="å°èªªè­¯é–± Pro - å¤œé–“ç‰ˆ", page_icon="ğŸŒ™", layout="centered")

# 2. CSSï¼šç¶­æŒå¤œé–“æ²‰æµ¸å¼æ’ç‰ˆ
st.markdown("""
    <style>
    .stApp { background-color: #0F0F0F; color: #E0E0E0; } 
    .novel-container {
        max-width: 850px;
        margin: 20px auto;
        padding: 50px 40px;
        background-color: #1A1A1A;
        border: 1px solid #333333;
        border-radius: 16px;
        box-shadow: 0 15px 35px rgba(0,0,0,0.6);
    }
    .novel-title {
        font-family: "Noto Serif TC", serif;
        color: #FFFFFF;
        text-align: center;
        border-bottom: 2px solid #2D2D2D;
        padding-bottom: 30px;
        margin-bottom: 40px;
        font-size: 2.2rem;
    }
    .paragraph-block { margin-bottom: 35px; line-height: 2.0; }
    .zh-content {
        font-size: 1.3rem;
        color: #D6D6D6;
        text-indent: 2.5em; 
        font-family: "Microsoft JhengHei", sans-serif;
    }
    .jp-orig {
        display: block;
        font-size: 0.95rem;
        color: #666666;
        margin-top: 10px;
        text-indent: 0;
        font-style: italic;
        border-left: 3px solid #4A90E2;
        padding-left: 15px;
    }
    .stTextInput input { background-color: #262626 !important; color: #FFFFFF !important; }
    #MainMenu, footer { visibility: hidden; }
    </style>
    """, unsafe_allow_html=True)

# 3. æ ¸å¿ƒé‚è¼¯ï¼šå„ªåŒ–ç©ºç™½è™•ç†èˆ‡è´…è©å‰”é™¤
def translate_novel_content(text_list):
    if not text_list: return []
    
    # è´…è©æ¸…å–®
    blacklist = ['ä¸‹ä¸€é ', 'ä¸‹ä¸€ä¸€å€‹', 'å‰ä¸€é ', 'æ¬¡ã¸', 'å‰ã¸', 'ç›®æ¬¡', 'ç™¼ç”ŸéŒ¯èª¤', 'åŠ å…¥æ›¸ç±¤', 'å»£å‘Š']
    
    cleaned_list = []
    for t in text_list:
        # é‚è¼¯ Aï¼šå¦‚æœæ˜¯ç´”ç©ºç™½ï¼ˆå«å…¨å½¢ã€åŠå½¢ã€æ›è¡Œï¼‰ï¼Œç›´æ¥ä¿ç•™åŸå§‹ç©ºç™½ä¸ç¿»è­¯
        if not t.strip():
            cleaned_list.append(t)
            continue
        # é‚è¼¯ Bï¼šå‰”é™¤é»‘åå–®è´…è©
        if any(noise in t for noise in blacklist):
            continue
        cleaned_list.append(t)
    
    if not cleaned_list: return []

    # æ‰¹æ¬¡ç¿»è­¯ï¼Œä½†è·³éç´”ç©ºç™½çš„æ®µè½
    translated_results = []
    for t in cleaned_list:
        if not t.strip():
            translated_results.append("&nbsp;") # ç›´æ¥ç”¨ HTML ç©ºæ ¼ä»£è¡¨ç©ºç™½è™•
        else:
            try:
                # ç¿»è­¯å–®ä¸€æœ‰æ•ˆæ®µè½ï¼Œç¢ºä¿ä¸æœƒæŠŠç©ºç™½è™•è½‰æˆç¬¦è™Ÿ
                res = GoogleTranslator(source='ja', target='zh-TW').translate(t)
                translated_results.append(res)
            except:
                translated_results.append(t)
                
    return cleaned_list, translated_results

# 4. ä¸»ç¨‹å¼ä»‹é¢
st.markdown('<h1 style="text-align:center; color:#4A90E2;">ğŸŒ™ å°èªªè­¯é–±ï½œç´”æ·¨å¤œé–“æ¨¡å¼</h1>', unsafe_allow_html=True)
url = st.text_input("è«‹è¼¸å…¥æ—¥æ–‡å°èªªç¶²å€ï¼š", placeholder="https://ncode.syosetu.com...")

if url:
    try:
        with st.spinner("ğŸŒ™ æ­£åœ¨è™•ç†ç´”æ·¨æ’ç‰ˆä¸­..."):
            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
            res = requests.get(url, headers=headers, timeout=15)
            res.encoding = 'utf-8'
            soup = BeautifulSoup(res.text, 'lxml')

            main_content = soup.select_one('#novel_honbun, .novel_view, .episode-content, #story')
            if not main_content: main_content = soup

            raw_title = soup.title.string.split('ã€Œ')[-1].split('ã€')[0] if soup.title else "ç« ç¯€å…§å®¹"
            zh_title = GoogleTranslator(source='ja', target='zh-TW').translate(raw_title)

            st.markdown(f'<div class="novel-container"><h2 class="novel-title">{zh_title}</h2>', unsafe_allow_html=True)

            # æŠ“å–æ‰€æœ‰æ®µè½èˆ‡ç©ºè¡Œ
            paragraphs = [p.get_text() for p in main_content.find_all(['p', 'h1', 'h2'])]
            
            orig_cleaned, trans_list = translate_novel_content(paragraphs)
            
            for orig, tran in zip(orig_cleaned, trans_list):
                # å¦‚æœæ˜¯ç©ºç™½è™•ï¼Œå‰‡æ¸²æŸ“æˆç©ºè¡Œ
                if not orig.strip():
                    st.markdown('<br>', unsafe_allow_html=True)
                else:
                    st.markdown(f"""
                        <div class="paragraph-block">
                            <div class="zh-content">{tran}</div>
                            <div class="jp-orig">{orig}</div>
                        </div>
                    """, unsafe_allow_html=True)
            
            st.markdown('</div>', unsafe_allow_html=True)
            st.toast("âœ… ç´”æ·¨æ’ç‰ˆå·²å®Œæˆã€‚")

    except Exception as e:
        st.error("è§£æå¤±æ•—ï¼Œè«‹æª¢æŸ¥ç¶²å€æˆ–ç¨å¾Œå†è©¦ã€‚")
