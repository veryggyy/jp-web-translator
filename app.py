import streamlit as st
import requests
from bs4 import BeautifulSoup
from deep_translator import GoogleTranslator
import time

# 1. é é¢é…ç½®
st.set_page_config(page_title="å°èªªè­¯é–± Pro - å¤œé–“ç´”æ·¨ç‰ˆ", page_icon="ğŸŒ™", layout="centered")

# 2. å¤œé–“æ¨¡å¼ CSS
st.markdown("""
    <style>
    .stApp { background-color: #0F0F0F; color: #E0E0E0; } 
    .novel-container {
        max-width: 850px;
        margin: 20px auto;
        padding: 50px 40px;
        background-color: #1A1A1A;
        border: 1px solid #333333;
        border-radius: 16px;
        box-shadow: 0 15px 35px rgba(0,0,0,0.6);
    }
    .novel-title {
        font-family: "Noto Serif TC", serif;
        color: #FFFFFF;
        text-align: center;
        border-bottom: 2px solid #2D2D2D;
        padding-bottom: 30px;
        margin-bottom: 40px;
        font-size: 2.2rem;
    }
    .paragraph-block { margin-bottom: 30px; line-height: 2.0; }
    .zh-content { font-size: 1.25rem; color: #D6D6D6; text-indent: 2.5em; font-family: "Microsoft JhengHei", sans-serif; }
    .jp-orig { display: block; font-size: 0.9rem; color: #666666; margin-top: 8px; border-left: 3px solid #4A90E2; padding-left: 15px; font-style: italic; }
    #MainMenu, footer { visibility: hidden; }
    </style>
    """, unsafe_allow_html=True)

# 3. å„ªåŒ–å¾Œçš„ç¿»è­¯å¼•æ“ï¼šæ”¯æ´æ‰¹æ¬¡è™•ç†ä¸”ä¿ç•™ç©ºç™½
def batch_translate_safe(text_list):
    if not text_list: return []
    
    # éæ¿¾è´…è©
    blacklist = ['ä¸‹ä¸€é ', 'ä¸‹ä¸€ä¸€å€‹', 'å‰ä¸€é ', 'æ¬¡ã¸', 'å‰ã¸', 'ç›®æ¬¡', 'åŠ å…¥æ›¸ç±¤', 'ç™¼ç”ŸéŒ¯èª¤']
    
    # é è™•ç†ï¼šæ¨™è¨˜ç©ºç™½è™•ï¼Œåˆä½µæœ‰æ•ˆæ–‡å­—
    processed_list = []
    to_translate = []
    
    for t in text_list:
        clean_t = t.strip()
        # å¦‚æœæ˜¯ç©ºç™½æˆ–æ˜¯é»‘åå–®å­—çœ¼ï¼Œæ¨™è¨˜ç‚ºç‰¹æ®Šç¬¦è™Ÿè·³éç¿»è­¯
        if not clean_t or any(noise in clean_t for noise in blacklist):
            processed_list.append("__EMPTY_LINE__")
        else:
            processed_list.append(clean_t)
            to_translate.append(clean_t)
            
    if not to_translate:
        return [" " for _ in processed_list]

    # æ‰¹æ¬¡ç¿»è­¯æœ‰æ•ˆæ–‡å­— (ä½¿ç”¨åˆ†éš”ç¬¦è™Ÿæ¸›å°‘è«‹æ±‚æ¬¡æ•¸)
    try:
        combined = "\n\n###\n\n".join(to_translate)
        translated_all = GoogleTranslator(source='ja', target='zh-TW').translate(combined)
        translated_parts = translated_all.split("\n\n###\n\n")
    except:
        # å‚™æ´ï¼šè‹¥æ‰¹æ¬¡å¤±æ•—å‰‡å–®ç­†ç¿»è­¯
        translated_parts = [GoogleTranslator(source='ja', target='zh-TW').translate(t) for t in to_translate]

    # å°‡ç¿»è­¯å¥½çš„æ–‡å­—å¡«å›å°æ‡‰ä½ç½®ï¼Œç©ºç™½è™•ç¶­æŒç©ºç™½
    final_results = []
    ti = 0
    for item in processed_list:
        if item == "__EMPTY_LINE__":
            final_results.append(None) # None ä»£è¡¨ç©ºç™½
        else:
            final_results.append(translated_parts[ti] if ti < len(translated_parts) else item)
            ti += 1
    return final_results

# 4. ä¸»ç¨‹å¼ä»‹é¢
st.markdown('<h1 style="text-align:center; color:#4A90E2;">ğŸŒ™ å°èªªè­¯é–±ï½œç´”æ·¨å¤œé–“æ¨¡å¼</h1>', unsafe_allow_html=True)
url = st.text_input("è«‹è¼¸å…¥æ—¥æ–‡å°èªªç¶²å€ï¼š", placeholder="https://ncode.syosetu.com...")

if url:
    try:
        with st.spinner("ğŸŒ™ æ­£åœ¨ç¹éåµæ¸¬ä¸¦è§£æå…§å®¹..."):
            # å¼·åŒ– Header å½è£æˆçœŸå¯¦ç”¨æˆ¶
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept-Language': 'ja,en-US;q=0.9,en;q=0.8'
            }
            res = requests.get(url, headers=headers, timeout=20)
            res.raise_for_status() # å¦‚æœ 403 æˆ– 404 æœƒå ±éŒ¯
            res.encoding = 'utf-8'
            soup = BeautifulSoup(res.text, 'lxml')

            # å®šä½å°èªªä¸»é«”
            main_content = soup.select_one('#novel_honbun, .novel_view, .episode-content, #story')
            if not main_content:
                st.warning("âš ï¸ æ‰¾ä¸åˆ°æ¨™æº–å°èªªå€å¡Šï¼Œå˜—è©¦è§£æå…¨æ–‡ã€‚")
                main_content = soup

            # ç« ç¯€æ¨™é¡Œ
            raw_title = soup.title.string.replace(' - å°èª¬å®¶ã«ãªã‚ã†', '').strip() if soup.title else "ç« ç¯€å…§å®¹"
            zh_title = GoogleTranslator(source='ja', target='zh-TW').translate(raw_title)

            st.markdown(f'<div class="novel-container"><h2 class="novel-title">{zh_title}</h2>', unsafe_allow_html=True)

            # ç²å–æ‰€æœ‰æ®µè½
            raw_paragraphs = [p.get_text() for p in main_content.find_all(['p', 'h1', 'h2'])]
            
            # åˆ†æ‰¹è™•ç†ï¼ˆæ¯ 15 æ®µä¸€çµ„ï¼‰ï¼Œå¹³è¡¡é€Ÿåº¦èˆ‡æˆåŠŸç‡
            batch_size = 15
            for i in range(0, len(raw_paragraphs), batch_size):
                batch = raw_paragraphs[i:i+batch_size]
                translated_batch = batch_translate_safe(batch)
                
                for orig, tran in zip(batch, translated_batch):
                    if tran is None: # ç©ºç™½è™•
                        st.markdown('<br>', unsafe_allow_html=True)
                    else:
                        st.markdown(f"""
                            <div class="paragraph-block">
                                <div class="zh-content">{tran}</div>
                                <div class="jp-orig">{orig}</div>
                            </div>
                        """, unsafe_allow_html=True)
            
            st.markdown('</div>', unsafe_allow_html=True)
            st.toast("âœ… ç¿»è­¯å·²å®‰å…¨å®Œæˆã€‚")

    except Exception as e:
        st.error(f"âŒ è§£æå¤±æ•—ã€‚åŸå› ï¼š{str(e)}")
        st.info("æç¤ºï¼šå¦‚æœå‡ºç¾ 403 éŒ¯èª¤ï¼Œä»£è¡¨è©²ç¶²ç«™æš«æ™‚å°é–äº†æ‚¨çš„é€£ç·šï¼Œè«‹éå¹¾åˆ†é˜å†è©¦ã€‚")
